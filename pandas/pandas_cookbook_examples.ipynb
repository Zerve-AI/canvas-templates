{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for *short and sweet* examples and links for useful pandas recipes.\n",
    "\n",
    "Adding interesting links and/or inline examples to this section is a great *First Pull Request*.\n",
    "\n",
    "Simplified, condensed, new-user friendly, in-line examples have been inserted where possible to\n",
    "augment the Stack-Overflow and GitHub links.  Many of the links contain expanded information,\n",
    "above what the in-line examples offer.\n",
    "\n",
    "pandas (pd) and NumPy (np) are the only two abbreviated imported modules. The rest are kept\n",
    "explicitly imported for newer users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idioms -  If Then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An if-then on one column\n",
    "df.loc[df.AAA >= 5, \"BBB\"] = -1\n",
    "df\n",
    "\n",
    "#An if-then with assignment to 2 columns:\n",
    "df.loc[df.AAA >= 5, [\"BBB\", \"CCC\"]] = 555\n",
    "df\n",
    "\n",
    "#Add another line with different logic, to do the -else\n",
    "df.loc[df.AAA < 5, [\"BBB\", \"CCC\"]] = 2000\n",
    "df\n",
    "\n",
    "# Or use pandas where after you've set up a mask\n",
    "df_mask = pd.DataFrame(\n",
    "    {\"AAA\": [True] * 4, \"BBB\": [False] * 4, \"CCC\": [True, False] * 2}\n",
    ")\n",
    "df.where(df_mask, -1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if-then-else using NumPy's where()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n",
    "df[\"logic\"] = np.where(df[\"AAA\"] > 5, \"high\", \"low\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a frame with a boolean criterion\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n",
    "\n",
    "df[df.AAA <= 5]\n",
    "df[df.AAA > 5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select with multi-column criteria\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n",
    "\n",
    "# and (without assignment returns a Series)\n",
    "df.loc[(df[\"BBB\"] < 25) & (df[\"CCC\"] >= -40), \"AAA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or (without assignment returns a Series)\n",
    "df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= -40), \"AAA\"]\n",
    "\n",
    "# or (with assignment modifies the DataFrame.)\n",
    "df.loc[(df[\"BBB\"] > 25) | (df[\"CCC\"] >= 75), \"AAA\"] = 0.1\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with data closest to certain value using argsort\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n",
    "aValue = 43.0\n",
    "df.loc[(df.CCC - aValue).abs().argsort()]\n",
    "\n",
    "# Dynamically reduce a list of criteria using a binary operators\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Crit1 = df.AAA <= 5.5\n",
    "Crit2 = df.BBB == 10.0\n",
    "Crit3 = df.CCC > -40.0\n",
    "\n",
    "# One could hard code:\n",
    "AllCrit = Crit1 & Crit2 & Crit3\n",
    "\n",
    "# Or it can be done with a list of dynamically built criteria\n",
    "import functools\n",
    "CritList = [Crit1, Crit2, Crit3]\n",
    "AllCrit = functools.reduce(lambda x, y: x & y, CritList)\n",
    "\n",
    "df[AllCrit]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using both row labels and value conditionals\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n",
    "\n",
    "df[(df.AAA <= 6) & (df.index.isin([0, 2, 4]))]\n",
    "\n",
    "#Use loc for label-oriented slicing and iloc positional slicing :issue:`2904`\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]},\n",
    "    index=[\"foo\", \"bar\", \"boo\", \"kar\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2 explicit slicing methods, with a third general case\n",
    "\n",
    "# 1. Positional-oriented (Python slicing style : exclusive of end)\n",
    "df.iloc[0:3]  # Positional\n",
    "\n",
    "\n",
    "# 2. Label-oriented (Non-Python slicing style : inclusive of end)\n",
    "df.loc[\"bar\":\"kar\"]  # Label\n",
    "\n",
    "\n",
    "# 3. General (Either slicing style : depends on if the slice contains labels or positions)\n",
    "df[0:3]\n",
    "df[\"bar\":\"kar\"]\n",
    "\n",
    "# Ambiguity arises when an index consists of integers with a non-zero start or non-unit increment.\n",
    "data = {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    "df2 = pd.DataFrame(data=data, index=[1, 2, 3, 4])  # Note index starts at 1.\n",
    "df2.iloc[1:3]  # Position-oriented\n",
    "df2.loc[1:3]  # Label-oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using inverse operator (~) to take the complement of a mask\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "df\n",
    "\n",
    "df[~((df.AAA <= 6) & (df.index.isin([0, 2, 4])))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiently and dynamically creating new columns using applymap\n",
    "df = pd.DataFrame({\"AAA\": [1, 2, 1, 3], \"BBB\": [1, 1, 2, 2], \"CCC\": [2, 1, 3, 1]})\n",
    "df\n",
    "\n",
    "source_cols = df.columns  # Or some subset would work too\n",
    "new_cols = [str(x) + \"_cat\" for x in source_cols]\n",
    "categories = {1: \"Alpha\", 2: \"Beta\", 3: \"Charlie\"}\n",
    "\n",
    "df[new_cols] = df[source_cols].applymap(categories.get)\n",
    "df\n",
    "\n",
    "# Keep other columns when using min() with groupby\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [1, 1, 1, 2, 2, 2, 3, 3], \"BBB\": [2, 1, 3, 4, 5, 1, 2, 3]}\n",
    ")\n",
    "df\n",
    "\n",
    "# Method 1 : idxmin() to get the index of the minimums\n",
    "df.loc[df.groupby(\"AAA\")[\"BBB\"].idxmin()]\n",
    "\n",
    "# Method 2 : sort then take first of each\n",
    "df.sort_values(by=\"BBB\").groupby(\"AAA\", as_index=False).first()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a MultiIndex from a labeled frame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"row\": [0, 1, 2],\n",
    "        \"One_X\": [1.1, 1.1, 1.1],\n",
    "        \"One_Y\": [1.2, 1.2, 1.2],\n",
    "        \"Two_X\": [1.11, 1.11, 1.11],\n",
    "        \"Two_Y\": [1.22, 1.22, 1.22],\n",
    "    }\n",
    ")\n",
    "df\n",
    "\n",
    "# As Labelled Index\n",
    "df = df.set_index(\"row\")\n",
    "df\n",
    "# With Hierarchical Columns\n",
    "df.columns = pd.MultiIndex.from_tuples([tuple(c.split(\"_\")) for c in df.columns])\n",
    "df\n",
    "# Now stack & Reset\n",
    "df = df.stack(0).reset_index(1)\n",
    "df\n",
    "# And fix the labels (Notice the label 'level_1' got added automatically)\n",
    "df.columns = [\"Sample\", \"All_X\", \"All_Y\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic - Performing arithmetic with a MultiIndex that needs broadcasting\n",
    "cols = pd.MultiIndex.from_tuples(\n",
    "    [(x, y) for x in [\"A\", \"B\", \"C\"] for y in [\"O\", \"I\"]]\n",
    ")\n",
    "df = pd.DataFrame(np.random.randn(2, 6), index=[\"n\", \"m\"], columns=cols)\n",
    "df\n",
    "df = df.div(df[\"C\"], level=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing - Slicing a MultiIndex with xs\n",
    "coords = [(\"AA\", \"one\"), (\"AA\", \"six\"), (\"BB\", \"one\"), (\"BB\", \"two\"), (\"BB\", \"six\")]\n",
    "index = pd.MultiIndex.from_tuples(coords)\n",
    "df = pd.DataFrame([11, 22, 33, 44, 55], index, [\"MyData\"])\n",
    "df\n",
    "\n",
    "# To take the cross section of the 1st level and 1st axis the index:\n",
    "# Note : level and axis are optional, and default to zero\n",
    "df.xs(\"BB\", level=0, axis=0)\n",
    "\n",
    "# and now the 2nd level of the 1st axis.\n",
    "df.xs(\"six\", level=1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Slicing a MultiIndex with xs, method #2\n",
    "import itertools\n",
    "\n",
    "index = list(itertools.product([\"Ada\", \"Quinn\", \"Violet\"], [\"Comp\", \"Math\", \"Sci\"]))\n",
    "headr = list(itertools.product([\"Exams\", \"Labs\"], [\"I\", \"II\"]))\n",
    "indx = pd.MultiIndex.from_tuples(index, names=[\"Student\", \"Course\"])\n",
    "cols = pd.MultiIndex.from_tuples(headr)  # Notice these are un-named\n",
    "data = [[70 + x + y + (x * y) % 3 for x in range(4)] for y in range(9)]\n",
    "df = pd.DataFrame(data, indx, cols)\n",
    "df\n",
    "\n",
    "All = slice(None)\n",
    "df.loc[\"Violet\"]\n",
    "df.loc[(All, \"Math\"), All]\n",
    "df.loc[(slice(\"Ada\", \"Quinn\"), \"Math\"), All]\n",
    "df.loc[(All, \"Math\"), (\"Exams\")]\n",
    "df.loc[(All, \"Math\"), (All, \"II\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill forward a reversed timeseries\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(6, 1),\n",
    "    index=pd.date_range(\"2013-08-01\", periods=6, freq=\"B\"),\n",
    "    columns=list(\"A\"),\n",
    ")\n",
    "df.loc[df.index[3], \"A\"] = np.nan\n",
    "df\n",
    "df.bfill()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic grouping with apply\n",
    "# Unlike agg, apply's callable is passed a sub-DataFrame which gives you access to all the columns\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"animal\": \"cat dog cat fish dog cat cat\".split(),\n",
    "        \"size\": list(\"SSMMMLL\"),\n",
    "        \"weight\": [8, 10, 11, 1, 20, 12, 12],\n",
    "        \"adult\": [False] * 5 + [True] * 2,\n",
    "    }\n",
    ")\n",
    "df\n",
    "\n",
    "# List the size of the animals with the highest weight.\n",
    "df.groupby(\"animal\").apply(lambda subf: subf[\"size\"][subf[\"weight\"].idxmax()])\n",
    "\n",
    "# Using get_group\n",
    "gb = df.groupby([\"animal\"])\n",
    "gb.get_group(\"cat\")\n",
    "\n",
    "# Apply to different items in a group\n",
    "def GrowUp(x):\n",
    "    avg_weight = sum(x[x[\"size\"] == \"S\"].weight * 1.5)\n",
    "    avg_weight += sum(x[x[\"size\"] == \"M\"].weight * 1.25)\n",
    "    avg_weight += sum(x[x[\"size\"] == \"L\"].weight)\n",
    "    avg_weight /= len(x)\n",
    "    return pd.Series([\"L\", avg_weight, True], index=[\"size\", \"weight\", \"adult\"])\n",
    "\n",
    "\n",
    "expected_df = gb.apply(GrowUp)\n",
    "expected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expanding apply\n",
    "S = pd.Series([i / 100.0 for i in range(1, 11)])\n",
    "\n",
    "def cum_ret(x, y):\n",
    "    return x * (1 + y)\n",
    "\n",
    "def red(x):\n",
    "    return functools.reduce(cum_ret, x, 1.0)\n",
    "\n",
    "S.expanding().apply(red, raw=True)\n",
    "\n",
    "\n",
    "# Replacing some values with mean of the rest of a group\n",
    "df = pd.DataFrame({\"A\": [1, 1, 2, 2], \"B\": [1, -1, 1, 2]})\n",
    "gb = df.groupby(\"A\")\n",
    "\n",
    "def replace(g):\n",
    "    mask = g < 0\n",
    "    return g.where(~mask, g[~mask].mean())\n",
    "\n",
    "gb.transform(replace)\n",
    "\n",
    "# Sort groups by aggregated data\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"code\": [\"foo\", \"bar\", \"baz\"] * 2,\n",
    "        \"data\": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],\n",
    "        \"flag\": [False, True] * 3,\n",
    "    }\n",
    ")\n",
    "\n",
    "code_groups = df.groupby(\"code\")\n",
    "\n",
    "agg_n_sort_order = code_groups[[\"data\"]].transform(sum).sort_values(by=\"data\")\n",
    "\n",
    "sorted_df = df.loc[agg_n_sort_order.index]\n",
    "\n",
    "sorted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create multiple aggregated columns\n",
    "rng = pd.date_range(start=\"2014-10-07\", periods=10, freq=\"2min\")\n",
    "ts = pd.Series(data=list(range(10)), index=rng)\n",
    "\n",
    "def MyCust(x):\n",
    "    if len(x) > 2:\n",
    "        return x[1] * 1.234\n",
    "    return pd.NaT\n",
    "\n",
    "mhc = {\"Mean\": np.mean, \"Max\": np.max, \"Custom\": MyCust}\n",
    "ts.resample(\"5min\").apply(mhc)\n",
    "ts\n",
    "\n",
    "# Create a value counts column and reassign back to the DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\"Color\": \"Red Red Red Blue\".split(), \"Value\": [100, 150, 50, 50]}\n",
    ")\n",
    "df\n",
    "df[\"Counts\"] = df.groupby([\"Color\"]).transform(len)\n",
    "df\n",
    "\n",
    "# Shift groups of the values in a column based on the index\n",
    "df = pd.DataFrame(\n",
    "    {\"line_race\": [10, 10, 8, 10, 10, 8], \"beyer\": [99, 102, 103, 103, 88, 100]},\n",
    "    index=[\n",
    "        \"Last Gunfighter\",\n",
    "        \"Last Gunfighter\",\n",
    "        \"Last Gunfighter\",\n",
    "        \"Paynter\",\n",
    "        \"Paynter\",\n",
    "        \"Paynter\",\n",
    "    ],\n",
    ")\n",
    "df\n",
    "df[\"beyer_shifted\"] = df.groupby(level=0)[\"beyer\"].shift(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select row with maximum value from each group\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"host\": [\"other\", \"other\", \"that\", \"this\", \"this\"],\n",
    "        \"service\": [\"mail\", \"web\", \"mail\", \"mail\", \"web\"],\n",
    "        \"no\": [1, 2, 1, 2, 1],\n",
    "    }\n",
    ").set_index([\"host\", \"service\"])\n",
    "mask = df.groupby(level=0).agg(\"idxmax\")\n",
    "df_count = df.loc[mask[\"no\"]].reset_index()\n",
    "df_count\n",
    "\n",
    "# Grouping like Python's itertools.groupby\n",
    "df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=[\"A\"])\n",
    "df[\"A\"].groupby((df[\"A\"] != df[\"A\"].shift()).cumsum()).groups\n",
    "df[\"A\"].groupby((df[\"A\"] != df[\"A\"].shift()).cumsum()).cumsum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting a frame\n",
    "# Create a list of dataframes, split using a delineation based on logic included in rows.\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Case\": [\"A\", \"A\", \"A\", \"B\", \"A\", \"A\", \"B\", \"A\", \"A\"],\n",
    "        \"Data\": np.random.randn(9),\n",
    "    }\n",
    ")\n",
    "\n",
    "dfs = list(\n",
    "    zip(\n",
    "        *df.groupby(\n",
    "            (1 * (df[\"Case\"] == \"B\"))\n",
    "            .cumsum()\n",
    "            .rolling(window=3, min_periods=1)\n",
    "            .median()\n",
    "        )\n",
    "    )\n",
    ")[-1]\n",
    "\n",
    "dfs[0]\n",
    "dfs[1]\n",
    "dfs[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial sums and subtotals\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Province\": [\"ON\", \"QC\", \"BC\", \"AL\", \"AL\", \"MN\", \"ON\"],\n",
    "        \"City\": [\n",
    "            \"Toronto\",\n",
    "            \"Montreal\",\n",
    "            \"Vancouver\",\n",
    "            \"Calgary\",\n",
    "            \"Edmonton\",\n",
    "            \"Winnipeg\",\n",
    "            \"Windsor\",\n",
    "        ],\n",
    "        \"Sales\": [13, 6, 16, 8, 4, 3, 1],\n",
    "    }\n",
    ")\n",
    "table = pd.pivot_table(\n",
    "    df,\n",
    "    values=[\"Sales\"],\n",
    "    index=[\"Province\"],\n",
    "    columns=[\"City\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=True,\n",
    ")\n",
    "table.stack(\"City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency table like plyr in R\n",
    "grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": [\"x%d\" % r for r in range(10)],\n",
    "        \"Gender\": [\"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n",
    "        \"ExamYear\": [\n",
    "            \"2007\",\n",
    "            \"2007\",\n",
    "            \"2007\",\n",
    "            \"2008\",\n",
    "            \"2008\",\n",
    "            \"2008\",\n",
    "            \"2008\",\n",
    "            \"2009\",\n",
    "            \"2009\",\n",
    "            \"2009\",\n",
    "        ],\n",
    "        \"Class\": [\n",
    "            \"algebra\",\n",
    "            \"stats\",\n",
    "            \"bio\",\n",
    "            \"algebra\",\n",
    "            \"algebra\",\n",
    "            \"stats\",\n",
    "            \"stats\",\n",
    "            \"algebra\",\n",
    "            \"bio\",\n",
    "            \"bio\",\n",
    "        ],\n",
    "        \"Participated\": [\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"no\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "        ],\n",
    "        \"Passed\": [\"yes\" if x > 50 else \"no\" for x in grades],\n",
    "        \"Employed\": [\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "        ],\n",
    "        \"Grade\": grades,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.groupby(\"ExamYear\").agg(\n",
    "    {\n",
    "        \"Participated\": lambda x: x.value_counts()[\"yes\"],\n",
    "        \"Passed\": lambda x: sum(x == \"yes\"),\n",
    "        \"Employed\": lambda x: sum(x),\n",
    "        \"Grade\": lambda x: sum(x) / len(x),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pandas DataFrame with year over year data\n",
    "# To create year and month cross tabulation:\n",
    "df = pd.DataFrame(\n",
    "    {\"value\": np.random.randn(36)},\n",
    "    index=pd.date_range(\"2011-01-01\", freq=\"M\", periods=36),\n",
    ")\n",
    "\n",
    "pd.pivot_table(\n",
    "    df, index=df.index.month, columns=df.index.year, values=\"value\", aggfunc=\"sum\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling apply to organize - Turning embedded lists into a MultiIndex frame\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"A\": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],\n",
    "        \"B\": [[\"a\", \"b\", \"c\"], [\"jj\", \"kk\"], [\"ccc\"]],\n",
    "    },\n",
    "    index=[\"I\", \"II\", \"III\"],\n",
    ")\n",
    "\n",
    "def SeriesFromSubList(aList):\n",
    "    return pd.Series(aList)\n",
    "\n",
    "df_orgz = pd.concat(\n",
    "    {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}\n",
    ")\n",
    "df_orgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling apply with a DataFrame returning a Series\n",
    "df = pd.DataFrame(\n",
    "    data=np.random.randn(2000, 2) / 10000,\n",
    "    index=pd.date_range(\"2001-01-01\", periods=2000),\n",
    "    columns=[\"A\", \"B\"],\n",
    ")\n",
    "df\n",
    "\n",
    "def gm(df, const):\n",
    "    v = ((((df[\"A\"] + df[\"B\"]) + 1).cumprod()) - 1) * const\n",
    "    return v.iloc[-1]\n",
    "\n",
    "s = pd.Series(\n",
    "    {\n",
    "        df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)\n",
    "        for i in range(len(df) - 50)\n",
    "    }\n",
    ")\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rolling apply with a DataFrame returning a Scalar\n",
    "rng = pd.date_range(start=\"2014-01-01\", periods=100)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Open\": np.random.randn(len(rng)),\n",
    "        \"Close\": np.random.randn(len(rng)),\n",
    "        \"Volume\": np.random.randint(100, 2000, len(rng)),\n",
    "    },\n",
    "    index=rng,\n",
    ")\n",
    "df\n",
    "\n",
    "def vwap(bars):\n",
    "    return (bars.Close * bars.Volume).sum() / bars.Volume.sum()\n",
    "\n",
    "window = 5\n",
    "s = pd.concat(\n",
    "    [\n",
    "        (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))\n",
    "        for i in range(len(df) - window)\n",
    "    ]\n",
    ")\n",
    "s.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two dataframes with overlapping index (emulate R rbind)\n",
    "rng = pd.date_range(\"2000-01-01\", periods=6)\n",
    "df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=[\"A\", \"B\", \"C\"])\n",
    "df2 = df1.copy()\n",
    "\n",
    "#Depending on df construction, ignore_index may be needed\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df\n",
    "\n",
    "# Self Join of a DataFrame\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Area\": [\"A\"] * 5 + [\"C\"] * 2,\n",
    "        \"Bins\": [110] * 2 + [160] * 3 + [40] * 2,\n",
    "        \"Test_0\": [0, 1, 0, 1, 2, 0, 1],\n",
    "        \"Data\": np.random.randn(7),\n",
    "    }\n",
    ")\n",
    "df\n",
    "\n",
    "df[\"Test_1\"] = df[\"Test_0\"] - 1\n",
    "\n",
    "pd.merge(\n",
    "    df,\n",
    "    df,\n",
    "    left_on=[\"Bins\", \"Area\", \"Test_0\"],\n",
    "    right_on=[\"Bins\", \"Area\", \"Test_1\"],\n",
    "    suffixes=(\"_L\", \"_R\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
