{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series by passing a list of values, letting pandas create a default integer index:\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s\n",
    "\n",
    "# Creating a DataFrame by passing a NumPy array, with a datetime index using date_range() and labeled columns:\n",
    "dates = pd.date_range(\"20130101\", periods=6)\n",
    "dates\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "df\n",
    "\n",
    "# Creating a DataFrame by passing a dictionary of objects that can be converted into a series-like structure:\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": 1.0,\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        \"F\": \"foo\",\n",
    "    }\n",
    ")\n",
    "df2\n",
    "\n",
    "# The columns of the resulting DataFrame have different dtypes:\n",
    "df2.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:\n",
    "df.head()\n",
    "df.tail(3)\n",
    "\n",
    "# Display the DataFrame.index or DataFrame.columns:\n",
    "df.index\n",
    "df.columns\n",
    "\n",
    "# convert to numpy\n",
    "df.to_numpy()\n",
    "\n",
    "# For df2, the DataFrame with multiple dtypes, DataFrame.to_numpy() is relatively expensive:\n",
    "df2.to_numpy()\n",
    "\n",
    "# describe() shows a quick statistic summary of your data:\n",
    "df.describe()\n",
    "\n",
    "# Transposing your data:\n",
    "df.T\n",
    "\n",
    "# DataFrame.sort_index() sorts by an axis:\n",
    "df.sort_index(axis=1, ascending=False)\n",
    "\n",
    "# DataFrame.sort_values() sorts by values:\n",
    "df.sort_values(by=\"B\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select via the position of the passed integers:\n",
    "df.iloc[3]\n",
    "\n",
    "# By integer slices, acting similar to NumPy/Python:\n",
    "df.iloc[3:5, 0:2]\n",
    "\n",
    "# By lists of integer position locations, similar to the NumPy/Python style:\n",
    "df.iloc[[1, 2, 4], [0, 2]]\n",
    "\n",
    "#For slicing rows explicitly:\n",
    "df.iloc[1:3, :]\n",
    "\n",
    "#For slicing columns explicitly:\n",
    "df.iloc[:, 1:3]\n",
    "\n",
    "#For getting a value explicitly:\n",
    "df.iloc[1, 1]\n",
    "\n",
    "#For getting fast access to a scalar (equivalent to the prior method):\n",
    "df.iat[1, 1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a single column's values to select data:\n",
    "df[df[\"A\"] > 0]\n",
    "\n",
    "#Selecting values from a DataFrame where a boolean condition is met:\n",
    "df[df > 0]\n",
    "\n",
    "#Using the ~Series.isin method for filtering:\n",
    "df2 = df.copy()\n",
    "df2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]\n",
    "df2\n",
    "df2[df2[\"E\"].isin([\"two\", \"four\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Setting a new column automatically aligns the data by the indexes:\n",
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(\"20130102\", periods=6))\n",
    "s1\n",
    "df[\"F\"] = s1\n",
    "\n",
    "#Setting values by label\n",
    "df.at[dates[0], \"A\"] = 0\n",
    "\n",
    "\n",
    "#Setting values by position\n",
    "df.iat[0, 1] = 0\n",
    "\n",
    "\n",
    "#Setting by assigning with a NumPy array\n",
    "df.loc[:, \"D\"] = np.array([5] * len(df))\n",
    "\n",
    "#The result of the prior setting operations\n",
    "df\n",
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data\n",
    "\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [\"E\"])\n",
    "df1.loc[dates[0] : dates[1], \"E\"] = 1\n",
    "df1\n",
    "\n",
    "# DataFrame.dropna drops any rows that have missing data:\n",
    "df1.dropna(how=\"any\")\n",
    "\n",
    "# DataFrame.fillna fills missing data:\n",
    "df1.fillna(value=5)\n",
    "\n",
    "# isna gets the boolean mask where values are nan\n",
    "pd.isna(df1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing a descriptive statistic:\n",
    "df.mean()\n",
    "\n",
    "#Same operation on the other axis:\n",
    "df.mean(1)\n",
    "\n",
    "#Operating with objects that have different dimensionality and need alignment.\n",
    "#In addition, pandas automatically broadcasts along the specified dimension:\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)\n",
    "s\n",
    "df.sub(s, axis=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame.apply applies a user defined function to the data:\n",
    "df.apply(np.cumsum)\n",
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See more at Histogramming and Discretization\n",
    "\n",
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s\n",
    "s.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])\n",
    "s.str.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge - Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenating pandas objects together along an axis with concat\n",
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "df\n",
    "\n",
    "# break it into pieces\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "\n",
    "pd.concat(pieces)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge - Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge enables SQL style join types along specific columns\n",
    "left = pd.DataFrame({\"key\": [\"foo\", \"foo\"], \"lval\": [1, 2]})\n",
    "right = pd.DataFrame({\"key\": [\"foo\", \"foo\"], \"rval\": [4, 5]})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on=\"key\")\n",
    "\n",
    "# Another example that can be given is:\n",
    "\n",
    "left = pd.DataFrame({\"key\": [\"foo\", \"bar\"], \"lval\": [1, 2]})\n",
    "right = pd.DataFrame({\"key\": [\"foo\", \"bar\"], \"rval\": [4, 5]})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on=\"key\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By \"group by\" we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "# Splitting the data into groups based on some criteria\n",
    "# Applying a function to each group independently\n",
    "# Combining the results into a data structure\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    }\n",
    ")\n",
    "df\n",
    "\n",
    "# Grouping and then applying the pandas.core.groupby.DataFrameGroupBy.sum function to the resulting groups\n",
    "\n",
    "df.groupby(\"A\")[[\"C\", \"D\"]].sum()\n",
    "\n",
    "# Grouping by multiple columns forms a hierarchical index, and again we can apply the pandas.core.groupby.DataFrameGroupBy.sum function:\n",
    "df.groupby([\"A\", \"B\"]).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = list(\n",
    "    zip(\n",
    "        [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n",
    "        [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n",
    "    )\n",
    ")\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"first\", \"second\"])\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[\"A\", \"B\"])\n",
    "df2 = df[:4]\n",
    "df2\n",
    "\n",
    "# DataFrame.stack method \"compresses\" a level in the DataFrame's columns:\n",
    "\n",
    "stacked = df2.stack()\n",
    "stacked\n",
    "\n",
    "\n",
    "# With a \"stacked\" DataFrame or Series (having a MultiIndex as the index), the inverse operation of DataFrame.stack is DataFrame.unstack, which by default unstacks the last level\n",
    "\n",
    "stacked.unstack()\n",
    "stacked.unstack(1)\n",
    "stacked.unstack(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping - Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"one\", \"one\", \"two\", \"three\"] * 3,\n",
    "        \"B\": [\"A\", \"B\", \"C\"] * 4,\n",
    "        \"C\": [\"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\"] * 2,\n",
    "        \"D\": np.random.randn(12),\n",
    "        \"E\": np.random.randn(12),\n",
    "    }\n",
    ")\n",
    "df\n",
    "\n",
    "#pivot_table pivots a DataFrame specifying the values, index and columns\n",
    "\n",
    "\n",
    "\n",
    "pd.pivot_table(df, values=\"D\", index=[\"A\", \"B\"], columns=[\"C\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data).\n",
    "# This is extremely common in, but not limited to, financial applications\n",
    "\n",
    "rng = pd.date_range(\"1/1/2012\", periods=100, freq=\"S\")\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts.resample(\"5Min\").sum()\n",
    "\n",
    "# Series.tz_localize localizes a time series to a time zone:\n",
    "rng = pd.date_range(\"3/6/2012 00:00\", periods=5, freq=\"D\")\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "ts\n",
    "ts_utc = ts.tz_localize(\"UTC\")\n",
    "ts_utc\n",
    "\n",
    "\n",
    "# Series.tz_convert converts a timezones aware time series to another time zone:\n",
    "ts_utc.tz_convert(\"US/Eastern\")\n",
    "\n",
    "# Converting between time span representations:\n",
    "rng = pd.date_range(\"1/1/2012\", periods=5, freq=\"M\")\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts\n",
    "ps = ts.to_period()\n",
    "ps\n",
    "ps.to_timestamp()\n",
    "\n",
    "# Converting between period and timestamp enables some convenient arithmetic functions to be used. \n",
    "# In the following example, we convert a quarterly frequency with year ending in November to 9am of the end of the month following the quarter end:\n",
    "prng = pd.period_range(\"1990Q1\", \"2000Q4\", freq=\"Q-NOV\")\n",
    "ts = pd.Series(np.random.randn(len(prng)), prng)\n",
    "ts.index = (prng.asfreq(\"M\", \"e\") + 1).asfreq(\"H\", \"s\") + 9\n",
    "ts.head()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas can include categorical data in a DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\"id\": [1, 2, 3, 4, 5, 6], \"raw_grade\": [\"a\", \"b\", \"b\", \"a\", \"a\", \"e\"]}\n",
    ")\n",
    "\n",
    "\n",
    "# Converting the raw grades to a categorical data type:\n",
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
    "df[\"grade\"]\n",
    "\n",
    "# Rename the categories to more meaningful names:\n",
    "new_categories = [\"very good\", \"good\", \"very bad\"]\n",
    "df[\"grade\"] = df[\"grade\"].cat.rename_categories(new_categories)\n",
    "\n",
    "#Reorder the categories and simultaneously add the missing categories (methods under Series.cat return a new Series by default):\n",
    "df[\"grade\"] = df[\"grade\"].cat.set_categories(\n",
    "    [\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"]\n",
    ")\n",
    "df[\"grade\"]\n",
    "\n",
    "# Sorting is per order in the categories, not lexical order:\n",
    "df.sort_values(by=\"grade\")\n",
    "\n",
    "# Grouping by a categorical column with observed=False also shows empty categories:\n",
    "df.groupby(\"grade\", observed=False).size()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the standard convention for referencing the matplotlib API\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close(\"all\")\n",
    "\n",
    "# The plt.close method is used to close a figure window:\n",
    "\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\", periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot();\n",
    "plt.show();\n",
    "\n",
    "# On a DataFrame, the DataFrame.plot method is a convenience to plot all of the columns with labels:\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(1000, 4), index=ts.index, columns=[\"A\", \"B\", \"C\", \"D\"]\n",
    ")\n",
    "\n",
    "df = df.cumsum()\n",
    "\n",
    "plt.figure();\n",
    "df.plot();\n",
    "plt.legend(loc='best');\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
